# EchoV2 - Modular AI Chat Platform

A modular, extensible desktop application built with **Tauri**, **React**, **TypeScript**, and **Python FastAPI** featuring a plugin-based architecture for AI model providers. Chat with local and cloud AI models through a unified interface.

## âœ¨ Features

- ğŸ“¦ **Standalone Mac App** - Single-click installation with bundled Python backend
- ğŸš€ **Zero-Dependency Deployment** - No Python or package installation required for end users
- ğŸ¯ **First-Time Setup Wizard** - "Start chatting in 30 seconds" with guided provider configuration
- ğŸ’¬ **Conversation Management** - Full conversation workspace with sidebar, search, and persistence
- ğŸ§© **Advanced Plugin Architecture** - Hot-swappable AI providers with zero-restart deployment
- ğŸ”„ **Real-time Streaming** - All AI responses stream character-by-character for optimal UX
- ğŸ› ï¸ **Runtime Management** - Plugin discovery, configuration updates, and health monitoring via API
- ğŸ¯ **Type Safety** - Full TypeScript integration across frontend with comprehensive validation
- âš™ï¸ **Configuration Management** - Environment-based YAML with runtime updates and validation
- ğŸ”Œ **Multi-Provider Support** - OpenAI GPT, Anthropic Claude, and local Ollama models
- ğŸ–¥ï¸ **Desktop Native** - Cross-platform desktop app with Tauri
- ğŸ”’ **Local-First** - Support for local AI models (Ollama) and privacy
- ğŸ’¾ **SQLite Persistence** - Automatic conversation and message storage with cross-platform support
- ğŸ“¡ **Developer Tools** - Plugin template generator and comprehensive API documentation

### ğŸ†• **Latest Features**
- ğŸ”„ **Streaming-First Architecture** - All responses now stream by default for optimal user experience
- ğŸ¯ **Simplified UI** - Removed complexity with unified streaming interface
- ğŸ” **Enhanced Error Handling** - Custom error types with retry logic and user-friendly messages
- ğŸ›¡ï¸ **XSS Protection** - Complete HTML sanitization pipeline with input validation
- ğŸš« **Memory Leak Prevention** - Comprehensive cleanup for timeouts, API requests, and effects
- âš¡ **Performance Optimizations** - Debounced search, request deduplication, and React.memo
- ğŸ› ï¸ **Error Boundaries** - React error catching with automatic recovery
- ğŸ“ **Input Validation** - Client-side validation with security pattern detection
- ğŸ”„ **Request Management** - AbortController cleanup and race condition prevention
- ğŸ“š **JSDoc Documentation** - Comprehensive API documentation for maintainability

## ğŸ—ï¸ Architecture Overview

EchoV2 uses a **modular plugin architecture** that separates concerns and enables easy extensibility:

### Backend Architecture
```
backend/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ models/           # AbstractAIProvider interface, registry & manager
â”‚   â”œâ”€â”€ plugins/          # AI provider implementations
â”‚   â”‚   â”œâ”€â”€ ollama_provider.py     # Local AI via Ollama
â”‚   â”‚   â”œâ”€â”€ openai_provider.py     # OpenAI GPT models
â”‚   â”‚   â””â”€â”€ anthropic_provider.py  # Anthropic Claude models
â”‚   â””â”€â”€ database/         # SQLite persistence layer
â”‚       â”œâ”€â”€ config.py     # Database configuration & user data paths
â”‚       â”œâ”€â”€ session.py    # Async SQLAlchemy session management
â”‚       â””â”€â”€ models.py     # Database models (conversations, messages)
â”œâ”€â”€ services/             # Business logic layer
â”‚   â”œâ”€â”€ chat_service.py   # Chat logic with auto-persistence
â”‚   â”œâ”€â”€ conversation_service.py  # Database operations
â”‚   â””â”€â”€ health_service.py # System health monitoring
â”œâ”€â”€ api/routes/           # RESTful API endpoints
â”‚   â”œâ”€â”€ chat.py          # Chat completion endpoints (now with persistence)
â”‚   â”œâ”€â”€ conversations.py # Conversation management API
â”‚   â”œâ”€â”€ health.py        # System health monitoring
â”‚   â””â”€â”€ plugins.py       # Plugin management API
â”œâ”€â”€ utils/               # Developer tools
â”‚   â””â”€â”€ plugin_template.py # Plugin template generator
â”œâ”€â”€ tests/               # Comprehensive test suite (NEW!)
â”‚   â”œâ”€â”€ conftest.py      # Test fixtures and setup
â”‚   â”œâ”€â”€ test_chat_service.py      # Unit tests for chat functionality
â”‚   â””â”€â”€ test_api_routes.py        # API integration tests
â””â”€â”€ config/              # Settings and configuration management
```

### Frontend Architecture
```
src/
â”œâ”€â”€ types/               # TypeScript interfaces
â”œâ”€â”€ services/            # API client & business services
â”‚   â””â”€â”€ secure-storage/  # Secure API key storage service (NEW!)
â”œâ”€â”€ hooks/               # Custom React hooks (useChat, useConfig)
â”‚   â””â”€â”€ __tests__/       # Frontend test suite (NEW!)
â”œâ”€â”€ test/                # Test utilities and setup (NEW!)
â””â”€â”€ components/          # React UI components
```

## ğŸ”„ Real-time Streaming

EchoV2 features **streaming-first architecture** that delivers all AI responses character by character for an engaging, real-time chat experience.

### âœ¨ **Key Features**

- **ğŸ¯ Real-time Response Building** - All AI responses appear immediately and build character by character
- **ğŸ¨ Visual Indicators** - Animated typing cursor and streaming progress indicators
- **ğŸš« Memory Safe** - Proper cleanup of streams, timeouts, and AbortControllers
- **âš¡ Performance Optimized** - Efficient chunk processing with minimal re-renders
- **ğŸ›¡ï¸ Error Resilient** - Comprehensive error handling with graceful recovery
- **ğŸ¯ Simplified UX** - Single, consistent interface without toggle complexity

### ğŸ› ï¸ **Technical Implementation**

**Backend (Python FastAPI)**
```python
# Server-Sent Events streaming endpoint (always streams)
@router.post("/chat")
async def chat_completion(request: ChatRequestModel):
    generator = chat_service.send_message_stream(...)
    return StreamingResponse(create_sse_stream(generator), ...)
```

**Frontend (React + TypeScript)**
```typescript
// Simplified useChat hook (streaming-only)
const { 
  messages, 
  isStreaming, 
  streamingMessage, 
  sendStreamingMessage 
} = useChat()

// All responses stream in real-time
await sendStreamingMessage("Tell me a story", "gpt-4", "openai")
```

**UI Components**
```tsx
// Real-time streaming display
<ChatWindow
  messages={messages}
  isStreaming={isStreaming}
  streamingMessage={streamingMessage}
/>
```

### ğŸ“‹ **Usage Examples**

**Streaming Request (Default)**
```bash
# All requests now stream by default
curl -X POST "http://localhost:8000/chat" \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Tell me a story", "provider": "openai"}'

# Response format (Server-Sent Events)
data: {"chunk": "Once", "type": "content"}
data: {"chunk": " upon", "type": "content"}  
data: {"chunk": " a", "type": "content"}
data: {"type": "done"}
```

**Frontend Integration**
```typescript
// Simplified component (always streams)
const MyChat = () => {
  const { sendStreamingMessage } = useChat()
  
  const handleSend = async (prompt: string) => {
    await sendStreamingMessage(prompt) // Always streams
  }
}
```

### ğŸ”§ **Configuration**

```typescript
// Streaming configuration options
const streamingConfig = {
  streamingTimeout: 60000,      // 60s total timeout
  chunkTimeout: 10000,          // 10s between chunks
  showTypingIndicator: true,    // Visual streaming indicator
  autoErrorRecovery: true       // Graceful error handling
}
```

**ğŸ“š Complete Documentation:** See [STREAMING_IMPLEMENTATION.md](STREAMING_IMPLEMENTATION.md) for detailed implementation guide.

## ğŸ›¡ï¸ Security & Reliability Features

EchoV2 includes enterprise-grade security and reliability features to ensure safe and robust operation:

### ğŸ” **Enhanced Error Handling**

**Custom Error Types with Smart Retry Logic** - Comprehensive error management system:

```typescript
// Custom error types for specific scenarios
class AuthError extends Error { readonly isRetryable = false }
class NetworkError extends Error { readonly isRetryable = true }
class RateLimitError extends Error { readonly retryAfter: number }

// Intelligent retry logic with exponential backoff
const delay = getRetryDelay(error, attempt) // Smart delay calculation
if (isRetryableError(error)) {
  // Retry with appropriate delay
}
```

### ğŸ›¡ï¸ **XSS Protection & Input Sanitization**

**Complete Security Pipeline** - Multi-layer protection against XSS and injection attacks:

```typescript
// HTML sanitization for safe display
const safeContent = sanitizeForDisplay(userMessage)
// Converts: "Hello\n<script>alert('xss')</script>"
// To: "Hello<br>&lt;script&gt;alert('xss')&lt;/script&gt;"

// Input validation with security checks
const validMessage = validateMessage(input, {
  maxLength: 10000,
  checkSuspiciousPatterns: true
})

// Debounced search with sanitization
const debouncedSearch = useDebounce(sanitizeSearchTerm(searchTerm), 300)
```

### ğŸš« **Memory Leak Prevention**

**Comprehensive Cleanup Management** - Prevents memory leaks and resource issues:

```typescript
// AbortController cleanup for API requests
useEffect(() => {
  return () => {
    if (abortControllerRef.current) {
      abortControllerRef.current.abort()
    }
    requestQueueRef.current.clear()
  }
}, [])

// Timeout cleanup for auto-generated titles
useEffect(() => {
  return () => {
    if (titleGenerationTimeoutRef.current) {
      clearTimeout(titleGenerationTimeoutRef.current)
    }
  }
}, [])
```

### âš¡ **Performance Optimizations**

**Smart Rendering and Request Management**:

```typescript
// React.memo for expensive components
const ChatWindow = React.memo(({ messages, isLoading }) => {
  // Optimized rendering
})

// Request deduplication prevents duplicate API calls
const requestKey = createRequestKey(url, options)
if (pendingRequests.has(requestKey)) {
  return pendingRequests.get(requestKey) // Return existing promise
}

// Debounced search prevents excessive filtering
const debouncedSearchTerm = useDebounce(searchTerm, 300)
```

### ğŸ› ï¸ **Error Boundaries & Recovery**

**React Error Boundaries with Automatic Recovery**:

```typescript
<ErrorBoundary 
  onError={(error, info) => logError(error)}
  fallback={<FallbackUI />}
>
  <ChatWindow />
</ErrorBoundary>

// Automatic retry with exponential backoff
const resetErrorBoundary = () => {
  setTimeout(() => {
    setState({ hasError: false })
  }, 100)
}
```

### ğŸ“ **Input Validation & Security**

**Client-side Security with Pattern Detection**:

```typescript
// Suspicious pattern detection
const suspiciousPatterns = [
  /<script\b[^<]*(?:(?!<\/script>)<[^<]*)*<\/script>/gi,
  /javascript:/gi,
  /on\w+\s*=/gi
]

// API key format validation
const validateApiKey = (key: string, provider: string) => {
  const patterns = {
    openai: /^sk-[a-zA-Z0-9]{48,}$/,
    anthropic: /^sk-ant-api03-[a-zA-Z0-9_-]{95}$/
  }
  // Validate against provider-specific patterns
}
```

### ğŸ”„ **Request Management & Race Condition Prevention**

**Advanced Request Lifecycle Management**:

```typescript
// Request deduplication with caching
private pendingRequests = new Map<string, Promise<Response>>()
private requestCache = new Map<string, { response: any; timestamp: number }>()

// Race condition prevention
const sendMessage = useCallback(async (prompt: string) => {
  const requestId = `${conversationId}-${prompt}-${model}`
  if (requestQueueRef.current.has(requestId)) {
    return // Prevent duplicate requests
  }
  // Process request...
}, [])
```

## ğŸ“¦ Standalone App (Recommended for Users)

**Want to just use EchoV2 without any setup?** Download the standalone Mac app!

### ğŸ¯ One-Click Installation

1. **Download** the latest `EchoV2.app` from [Releases](https://github.com/coltonbatts/EchoV2/releases)
2. **Drag** to Applications folder
3. **Double-click** to run - the Python backend starts automatically!

### âœ¨ What's Included

The standalone app bundles everything you need:
- âœ… Tauri frontend (React + TypeScript)
- âœ… Python FastAPI backend (PyInstaller executable)
- âœ… All dependencies and configurations
- âœ… Automatic backend process management
- âœ… First-time setup wizard with guided configuration
- âœ… No Python installation required

### ğŸ”§ Building Your Own Standalone App

Want to build the standalone app yourself? It's easy:

```bash
# Install prerequisites (Rust required)
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
source ~/.cargo/env

# Clone and build
git clone https://github.com/coltonbatts/EchoV2.git
cd EchoV2
npm install
npm run build:standalone
```

The app will be created at: `src-tauri/target/release/bundle/macos/EchoV2.app`

**ğŸ“š Detailed build instructions:** See [BUILD_INSTRUCTIONS.md](BUILD_INSTRUCTIONS.md)

---

## ğŸš€ Development Setup

### Prerequisites

- **Node.js** (v18+)
- **Python** (v3.8+) 
- **Rust** (for Tauri)
- **Ollama** (for local AI models)

### Installation

1. **Clone and install dependencies:**
```bash
git clone https://github.com/coltonbatts/EchoV2.git
cd EchoV2
npm install
```

2. **Set up Python backend:**
```bash
cd backend
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
cd ..
```

3. **Start Ollama (for local AI):**
```bash
ollama pull mistral
ollama serve
```

### Running the Application

1. **Start the backend:**
```bash
cd backend
source venv/bin/activate  # On Windows: venv\Scripts\activate
uvicorn main:app --reload
```

2. **Start the frontend:**
```bash
npm run tauri:dev
```

The application will open as a desktop app with the backend running at `http://localhost:8000`.

## ğŸ”Œ AI Provider Plugins

EchoV2's advanced plugin system supports hot-swappable AI providers with comprehensive management:

### Built-in Providers
- **ğŸ¦™ Ollama** - Local AI models (Mistral, Llama3, CodeLlama, Gemma, etc.)
  - âœ… Streaming responses
  - âœ… Multiple model support
  - âœ… Zero configuration for local development

- **ğŸ¤– OpenAI** - GPT models with full feature support
  - âœ… GPT-4, GPT-3.5-turbo variants
  - âœ… Streaming responses
  - âœ… Function calling
  - âœ… Vision capabilities

- **ğŸ§  Anthropic** - Claude models with advanced capabilities
  - âœ… Claude-3 (Opus, Sonnet, Haiku)
  - âœ… Claude-2 series
  - âœ… Streaming responses
  - âœ… Vision and multimodal support

### ğŸš€ Creating Custom Providers

**Method 1: Use the Plugin Template Generator (Recommended)**
```bash
cd backend
python utils/plugin_template.py \
  --name "custom-ai" \
  --display "Custom AI" \
  --url "https://api.custom-ai.com" \
  --model "custom-model-v1"
```

**Method 2: Manual Implementation**
```python
# backend/core/plugins/custom_provider.py
class CustomProvider(AbstractAIProvider):
    @property
    def metadata(self) -> PluginMetadata:
        return PluginMetadata(
            name="Custom Provider",
            capabilities=[PluginCapability.STREAMING],
            # ... other metadata
        )
    
    async def chat_completion(self, request: ChatRequest) -> ChatResponse:
        # Your implementation here
        pass
```

**Configuration & Registration**
```yaml
# config/development.yaml
ai_providers:
  custom:
    api_key: "your-api-key"
    base_url: "https://api.custom-ai.com"
    default_model: "custom-model-v1"
```

```python
# main.py
registry.register(CustomProvider, "custom")
```

## âš™ï¸ Configuration

### Environment-Based Configuration

EchoV2 uses YAML configuration files for different environments:

- `config/development.yaml` - Development settings
- `config/production.yaml` - Production settings

### Key Configuration Options

```yaml
server:
  host: "0.0.0.0"
  port: 8000
  debug: true

ai_providers:
  default: "ollama"
  ollama:
    base_url: "http://localhost:11434"
    default_model: "mistral"
    timeout: 60
  openai:
    api_key: ""  # Set your OpenAI API key
    default_model: "gpt-3.5-turbo"
    timeout: 60
  anthropic:
    api_key: ""  # Set your Anthropic API key
    default_model: "claude-3-sonnet-20240229"
    max_tokens: 4096

cors:
  allowed_origins: ["http://localhost:1420"]
```

## ğŸ’¬ Conversation Management

EchoV2 features a **comprehensive conversation workspace** that transforms the app from a stateless chat into a persistent conversation platform, allowing users to build complex, multi-turn conversations over time.

### ğŸ¯ **Key Features**
- **âœ… Conversation Sidebar** - Browse and manage all conversations with search functionality
- **âœ… Auto-Title Generation** - Intelligent titles automatically generated from first user message
- **âœ… Conversation Persistence** - Active conversation remembered across app sessions
- **âœ… Inline Editing** - Rename conversations directly in the sidebar
- **âœ… Search & Filter** - Find conversations by title or content preview
- **âœ… New Chat Functionality** - Easy access to start fresh conversations
- **âœ… Cross-Session Continuity** - Pick up conversations exactly where you left off

### ğŸ”„ **User Workflows**
1. **Start New Conversation** â†’ Auto-generates title â†’ Persists automatically
2. **Continue Previous Conversation** â†’ Click from sidebar â†’ Loads full history  
3. **Search Conversations** â†’ Filter by title or content preview
4. **Organize Conversations** â†’ Rename, delete, or browse by date
5. **Seamless Multi-Session** â†’ Active conversation remembered between app launches

### ğŸ“± **Interface Layout**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EchoV2 - Active Conversation Title  [Provider][Model]â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Sidebar     â”‚ Chat Messages                         â”‚
â”‚             â”‚                                       â”‚
â”‚ ğŸ” Search   â”‚ â”Œâ”€ User: Hello                        â”‚
â”‚             â”‚ â””â”€ AI: Hi! How can I help?            â”‚
â”‚ Conversationâ”‚                                       â”‚
â”‚ 1 â­        â”‚ â”Œâ”€ User: What's the weather?           â”‚
â”‚ Conversationâ”‚ â””â”€ AI: I don't have access to...       â”‚
â”‚ 2           â”‚                                       â”‚
â”‚ Conversationâ”‚                                       â”‚
â”‚ 3           â”‚                                       â”‚
â”‚             â”‚                                       â”‚
â”‚ [+ New]     â”‚ [Input field.....................] ğŸ“¤ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ’¾ SQLite Persistence

EchoV2 features **automatic conversation and message storage** with SQLite, providing seamless chat history without requiring any configuration.

### ğŸ”§ **Database Features**
- **âœ… Automatic Storage** - All messages saved transparently to SQLite database
- **âœ… Cross-Platform** - User data stored in appropriate OS-specific directories
- **âœ… Backward Compatible** - Existing API interface unchanged
- **âœ… Conversation Tracking** - Messages grouped by conversation with auto-generated titles
- **âœ… Rich Metadata** - Provider, model, usage stats, and timestamps stored
- **âœ… Zero Configuration** - Database created automatically on first run

### ğŸ“ **Database Location**
- **macOS**: `~/Library/Application Support/EchoV2/echo.db`
- **Windows**: `%APPDATA%\EchoV2\echo.db`
- **Linux**: `~/.local/share/EchoV2/echo.db`

### ğŸ”„ **How It Works**
1. **Send a message** via `/chat` endpoint
2. **User message** automatically saved to database
3. **AI response** saved with metadata (provider, model, usage)
4. **Conversation title** auto-generated from first message
5. **Conversation ID** returned in API response for tracking

### ğŸ“Š **Database Schema**
```sql
conversations (
    id INTEGER PRIMARY KEY,
    title TEXT,
    created_at TIMESTAMP,
    updated_at TIMESTAMP
)

messages (
    id INTEGER PRIMARY KEY,
    conversation_id INTEGER REFERENCES conversations(id),
    role TEXT,  -- 'user' or 'assistant'
    content TEXT,
    timestamp TIMESTAMP,
    provider TEXT,
    model TEXT,
    message_metadata JSON  -- Usage stats, finish_reason, etc.
)
```

### ğŸ”— **API Integration**
```bash
# Send message with optional conversation_id
curl -X POST "http://localhost:8000/chat" \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Hello!", "provider": "ollama", "conversation_id": 123}'

# Response includes conversation_id for tracking
{
  "response": "Hello! How can I help you today?",
  "model": "mistral",
  "provider": "ollama",
  "conversation_id": 123,
  "metadata": {...}
}
```

## ğŸ“¡ API Endpoints

### Chat Endpoints
- `POST /chat` - Send a message with streaming responses and persistence
- `POST /chat/conversation` - Send multi-turn conversation (now with persistence)
- `GET /chat/providers` - List available AI providers
- `GET /chat/providers/{provider}/models` - Get models for a provider

#### Streaming (Default)
```bash
# All requests stream by default (Server-Sent Events)
curl -X POST "http://localhost:8000/chat" \
  -d '{"prompt": "Hello", "provider": "openai"}'
```

### Conversation Management API
- `GET /conversations` - List all conversations with metadata and pagination
- `GET /conversations/{id}` - Get full conversation with all messages
- `DELETE /conversations/{id}` - Delete a conversation and all its messages
- `PUT /conversations/{id}/title` - Update conversation title
- `POST /conversations/{id}/generate-title` - Auto-generate title from first message

### Plugin Management API
- `GET /plugins/` - List all registered providers
- `GET /plugins/{name}/status` - Get provider health and status
- `POST /plugins/{name}/reload` - Hot-reload provider with new config
- `PUT /plugins/{name}/config` - Update provider configuration
- `GET /plugins/{name}/config-schema` - Get configuration schema
- `POST /plugins/discover` - Auto-discover plugins from directory
- `GET /plugins/health` - Health check all providers

### Health & Monitoring
- `GET /health` - System health check
- `GET /health/{provider}` - Provider-specific health check
- `GET /` - API information

## ğŸ¯ First-Time Setup Wizard

EchoV2 features a **modern setup wizard** that gets you chatting in 30 seconds, designed with the user experience of apps like Slack and Discord.

### âœ¨ **Key Features**
- **ğŸš€ "Start chatting in 30 seconds"** - Streamlined onboarding experience
- **ğŸ¯ Smart Provider Selection** - OpenAI, Anthropic, and Google with clear descriptions
- **ğŸ”— Direct API Key Links** - One-click access to provider signup pages
- **ğŸ”’ Real-time Validation** - Test API keys before saving configuration
- **âš™ï¸ Advanced Options** - Collapsible section for custom endpoints and local AI
- **ğŸ“Š Progress Tracking** - Visual progress bar and step indicators
- **ğŸ¨ Modern UI** - Gradient backgrounds, smooth animations, and responsive design

### ğŸ”„ **Setup Flow**
1. **Welcome Screen** â†’ Features overview and benefits
2. **Provider Selection** â†’ Choose from OpenAI, Anthropic, or Google
3. **API Key Input** â†’ Secure input with direct signup links
4. **Connection Test** â†’ Real-time validation and error handling
5. **Completion** â†’ Ready to start chatting!

### ğŸ› ï¸ **Technical Details**
- **localStorage Persistence** - Setup state saved across sessions
- **TypeScript Throughout** - Full type safety and error handling
- **Responsive Design** - Works perfectly on desktop
- **Configuration Integration** - Seamlessly integrates with existing config system

### Example Usage

```bash
# Send a chat message to specific provider (now with persistence)
curl -X POST "http://localhost:8000/chat" \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Hello, how are you?", "provider": "openai", "model": "gpt-4"}'

# Continue a conversation using conversation_id
curl -X POST "http://localhost:8000/chat" \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Tell me more", "provider": "openai", "conversation_id": 123}'

# List all conversations
curl "http://localhost:8000/conversations"

# Get a specific conversation with all messages
curl "http://localhost:8000/conversations/123"

# Update conversation title
curl -X PUT "http://localhost:8000/conversations/123/title" \
  -H "Content-Type: application/json" \
  -d '{"title": "My AI Research Session"}'

# Auto-generate conversation title
curl -X POST "http://localhost:8000/conversations/123/generate-title"

# Delete a conversation
curl -X DELETE "http://localhost:8000/conversations/123"

# All responses stream by default
curl -X POST "http://localhost:8000/chat" \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Tell me a story", "provider": "anthropic"}'

# Hot-reload a provider with new configuration
curl -X POST "http://localhost:8000/plugins/openai/reload" \
  -H "Content-Type: application/json" \
  -d '{"provider_name": "openai", "config": {"api_key": "sk-new-key...", "default_model": "gpt-4"}}'

# Check provider health
curl "http://localhost:8000/plugins/ollama/status"

# List all providers
curl "http://localhost:8000/plugins/"
```

## ğŸ› ï¸ Development

### Project Structure

```
EchoV2/
â”œâ”€â”€ config/                 # Configuration files
â”‚   â”œâ”€â”€ development.yaml
â”‚   â””â”€â”€ production.yaml
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ models/        # Base interfaces & registry
â”‚   â”‚   â””â”€â”€ plugins/       # AI provider implementations
â”‚   â”œâ”€â”€ services/          # Business logic (ChatService, HealthService)
â”‚   â”œâ”€â”€ api/routes/        # API endpoint definitions
â”‚   â””â”€â”€ config/            # Settings management
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ types/             # TypeScript interfaces
â”‚   â”œâ”€â”€ services/          # API client & business services
â”‚   â”œâ”€â”€ hooks/             # Custom React hooks
â”‚   â””â”€â”€ components/        # React UI components
â”œâ”€â”€ src-tauri/             # Tauri desktop configuration
â””â”€â”€ dist/                  # Built frontend assets
```

### Development Commands

```bash
# Frontend development with hot reload
npm run dev

# Backend development with auto-reload
cd backend && uvicorn main:app --reload

# Build for production
npm run build

# Build standalone Mac app
npm run build:standalone

# Run tests
npm test                          # Frontend tests (Vitest + RTL)
npm run test:ui                   # Frontend tests with UI
npm run test:coverage             # Frontend test coverage
cd backend && python -m pytest   # Backend tests (pytest)
cd backend && python -m pytest --cov  # Backend test coverage

# Type checking
npm run tsc

# Tauri development (desktop app)
npm run tauri:dev

# Build desktop app
npm run tauri:build
```

### Code Style & Standards

- **Backend**: Python with type hints, Pydantic for validation
- **Frontend**: TypeScript with strict mode, ESLint for linting
- **Architecture**: Clean Architecture with dependency injection
- **API**: RESTful design with OpenAPI/Swagger documentation

## ğŸ” Troubleshooting

### Common Issues

**Backend won't start:**
```bash
# Check Python dependencies
cd backend && pip install -r requirements.txt

# Verify configuration
cd backend && python -c "from config.settings import get_settings; print(get_settings())"
```

**Frontend build errors:**
```bash
# Clean install
rm -rf node_modules package-lock.json
npm install

# Check TypeScript
npm run tsc
```

**Ollama connection issues:**
```bash
# Check if Ollama is running
curl http://localhost:11434/api/tags

# Restart Ollama
ollama serve
```

**Provider not available:**
- Check provider configuration in YAML files
- Verify API keys and endpoints
- Check provider health: `curl http://localhost:8000/health/{provider}`

### Getting Help

- Check the [Issues](https://github.com/coltonbatts/EchoV2/issues) page
- Review configuration files for typos
- Ensure all dependencies are installed
- Check logs for detailed error messages

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to:

1. **Add new AI providers** - Implement `AbstractAIProvider` interface
2. **Improve UI/UX** - Enhance the React frontend
3. **Add features** - Multi-model chats, themes, authentication, etc.
4. **Fix bugs** - Check the issues page
5. **Improve documentation** - Help others understand the codebase

### Development Setup for Contributors

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/new-provider`
3. Make your changes following the existing patterns
4. Add tests if applicable
5. Submit a pull request

## ğŸ”¥ Plugin Architecture & Hot-Swapping

EchoV2 features a production-ready plugin architecture with zero-downtime management:

### ğŸš€ **Hot-Swapping Capabilities**
- **Zero-restart provider updates** - Change configurations without stopping the service
- **Dynamic plugin loading** - Add new providers at runtime
- **Automatic failover** - Health monitoring with seamless fallbacks
- **Configuration validation** - Real-time validation with detailed error reporting

### ğŸ› ï¸ **Developer Experience**
- **Plugin template generator** - Generate boilerplate with `python utils/plugin_template.py`
- **Comprehensive validation** - Type checking and configuration schema validation
- **Live debugging** - Health check endpoints and detailed logging
- **Auto-discovery** - Automatic detection of new plugins in directories

### ğŸ“š **Documentation**
- **[Plugin Architecture Guide](PLUGIN_ARCHITECTURE.md)** - Complete implementation guide
- **Configuration schemas** - Available via API endpoints
- **Best practices** - Type safety, error handling, and performance tips

## ğŸ“‹ Roadmap

### âœ… **Completed Features**
- [x] **Advanced Plugin Architecture** - Hot-swappable providers with runtime management âœ…
- [x] **ğŸ†• Streaming-First Architecture** - All responses stream by default for optimal UX âœ…
- [x] **ğŸ†• Simplified Streaming UI** - Unified interface without toggle complexity âœ…
- [x] **Multi-Provider Support** - OpenAI, Anthropic, Ollama integration âœ…
- [x] **Plugin Hot-Loading** - Dynamic plugin management âœ…
- [x] **Standalone Mac App** - PyInstaller + Tauri bundling with auto-backend management âœ…
- [x] **Message Persistence** - SQLite database integration for chat history âœ…
- [x] **Conversation Management** - Automatic conversation tracking and storage âœ…
- [x] **First-Time Setup Wizard** - Modern onboarding experience with guided configuration âœ…
- [x] **Enhanced Error Handling** - Custom error types with smart retry logic âœ…
- [x] **XSS Protection** - Complete HTML sanitization and input validation âœ…
- [x] **Memory Leak Prevention** - Comprehensive cleanup for timeouts and requests âœ…
- [x] **Performance Optimizations** - Debounced search, request deduplication, React.memo âœ…
- [x] **Error Boundaries** - React error catching with automatic recovery âœ…
- [x] **Request Management** - AbortController cleanup and race condition prevention âœ…
- [x] **JSDoc Documentation** - Comprehensive API documentation for maintainability âœ…

### ğŸš§ **Upcoming Features**
- [ ] **Multi-Model Chats** - Switch models mid-conversation
- [ ] **Theme System** - Customizable UI themes
- [ ] **Enhanced Authentication** - Advanced user management
- [ ] **Windows/Linux Standalone** - Cross-platform standalone builds
- [ ] **Export/Import** - Conversation backup and restore
- [ ] **Search & Analytics** - Advanced conversation search and usage analytics

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file for details.

---

**Built with â¤ï¸ using Tauri, React, TypeScript, and Python**